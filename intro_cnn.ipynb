{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59645c43",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Neural \n",
    "\n",
    "### why CNN ? \n",
    "#### -Ils sont généralement utilisés dans la taches de classification d'images . Les images sont souvent de dim 224*224 ou plus avec 3 chaines de couleurs -> ce qui fait 224*244 * 3 inputs pour les features . le réseau serait trop grand et presque impossible à bien entrainner .\n",
    "\n",
    "#### -pouvoir detecter l objet peut import la position "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf4bef",
   "metadata": {},
   "source": [
    "### Convolutions : \n",
    "#### ce sont des reseaux de neurones qui utilisent des couches convolutives ( conv layers) basé sur les opérations mathématiques des \"convolutiion\" . les conv layers sont un ensemble de filtres semblables à des matrices 2D\n",
    "\n",
    "#### Convolving le filtre( ex: sobel filter) avec l image : 1 . La superposition du filtre sur l'image à un endroit donné.  2. Multiplication par éléments entre les valeurs du filtre et leurs valeurs correspondantes dans l'image . 3 somme de tous les produits par élément. Cette somme est la valeur de sortie pour le pixel de destination dans l'image de sortie. 4 . repeter pour tous les locations \n",
    "\n",
    "#### -> le filtre de sobel est un détecteur de bord (edges) , le filtre vertical detecte les bords verticaux , l horizontal ... \n",
    "\n",
    "\n",
    "#### padding = ajouter des 0 sur les bords pour garder la meme taille d image a la sortie de la convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea98141",
   "metadata": {},
   "source": [
    "#### Conv Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61feba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "\n",
    "class Conv3x: \n",
    "    # une conv layer avec 3X3 filtres \n",
    "    def __init__(self , num_filters ):\n",
    "        self.num_filters = num_filters \n",
    "        #le filtre est un tableau 3D de taille \n",
    "        #on divise par 9 pour diminuer la variance\n",
    "        self.filters = np.random.randn(num_filters, 3, 3) / 9.0\n",
    "\n",
    "    def iterate_regions(self, image): \n",
    "        '''\n",
    "    Generates all possible 3x3 image regions using valid padding.\n",
    "    - image is a 2d numpy array\n",
    "    '''\n",
    "        h , w = image.shape \n",
    "        for i in range(h - 2):  \n",
    "            for  j in range(w - 2):\n",
    "                im_region = image[i : i + 3 , j : j + 3] ## 3x3 region of the image\n",
    "                yield im_region , i , j \n",
    "    \n",
    "    def forward(self, input): \n",
    "        '''\n",
    "        Performs a forward pass of the conv layer using the given input.\n",
    "        '''\n",
    "        h , w = input.shape\n",
    "        output = np.zeros((h - 2, w - 2, self.num_filters)) \n",
    "        for im_region, i, j in self.iterate_regions(input): \n",
    "            output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
    "        return output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc9980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 11:28:48.421978: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746264528.552887  125447 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746264528.591606  125447 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746264528.826898  125447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746264528.827082  125447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746264528.827087  125447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746264528.827091  125447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-03 11:28:48.886001: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(26, 26, 8)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "\n",
    "\n",
    "train_data = mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "conv = Conv3x(8)\n",
    "output = conv.forward(x_train[0])\n",
    "\n",
    "print(x_train[0].shape) # (28, 28)\n",
    "print(output.shape) # (26, 26, 8)\n",
    "# on a donc une image de 26x26 pixels et 8 canaux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284b69f",
   "metadata": {},
   "source": [
    "#### Pooling : \n",
    "##### les pixels voisins ont généralement des valeurs simimlaires , donc les conv layers vont prooduire des rsultats similaires pour les pixels voisins en sortie  . ce qui amene de la redondance dans les resulats . \n",
    "\n",
    "##### Pooling permet de resoudre ce probleme en reduisant  la taille de l'entrée qui leur est donnée en (vous l'avez deviné) regroupant les valeurs de l'entrée: par max , min ou moyenne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c465dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MaxPool2:\n",
    "  # A Max Pooling layer using a pool size of 2.\n",
    "\n",
    "  def iterate_regions(self, image):\n",
    "    '''\n",
    "    Generates non-overlapping 2x2 image regions to pool over.\n",
    "    - image is a 2d numpy array\n",
    "    '''\n",
    "    h, w, _ = image.shape\n",
    "    new_h = h // 2\n",
    "    new_w = w // 2\n",
    "\n",
    "    for i in range(new_h):\n",
    "      for j in range(new_w):\n",
    "        im_region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\n",
    "        yield im_region, i, j\n",
    "\n",
    "  def forward(self, input):\n",
    "    '''\n",
    "    Performs a forward pass of the maxpool layer using the given input.\n",
    "    Returns a 3d numpy array with dimensions (h / 2, w / 2, num_filters).\n",
    "    - input is a 3d numpy array with dimensions (h, w, num_filters)\n",
    "    '''\n",
    "    h, w, num_filters = input.shape\n",
    "    output = np.zeros((h // 2, w // 2, num_filters))\n",
    "\n",
    "    for im_region, i, j in self.iterate_regions(input):\n",
    "      output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "897d710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13, 8)\n"
     ]
    }
   ],
   "source": [
    "#teste de la couche maxpool\n",
    "\n",
    "conv = Conv3x(8)\n",
    "pool = MaxPool2()\n",
    "output = conv.forward(x_train[0])\n",
    "output = pool.forward(output)  # ca marche pas \n",
    "print(output.shape) # (13, 13, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f9a67",
   "metadata": {},
   "source": [
    "##### softmaw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ab933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax : \n",
    "    # une couche avec softmax \n",
    "    \n",
    "    def __init__(self, input_len, nodes ) :\n",
    "\n",
    "        self.weights = np.random.randn(input_len, nodes) / input_len \n",
    "\n",
    "        self.bias = np.zeros(nodes) \n",
    "\n",
    "\n",
    "\n",
    "    def forward( self , input): \n",
    "\n",
    "\n",
    "        #return un tableau 1D contenant les probas respectriuves \n",
    "        input = input.flatten() # regroupe les differents tableaux en un seul tableau 1D \n",
    "\n",
    "        input_len , nodes = self.weights.shape \n",
    "        totals = np.dot(input , self.weights) + self.bias \n",
    "\n",
    "        exp = np.exp(totals)\n",
    "\n",
    "        return exp / np.sum(exp, axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4c4c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist CNN\n",
      "Step :  99  Loss :  2.7085461154798782  Accuracy :  0.09\n",
      "Step :  199  Loss :  1.3453098491847886  Accuracy :  0.04\n",
      "Step :  299  Loss :  0.8968655078725934  Accuracy :  0.02\n",
      "Step :  399  Loss :  0.7055549718355639  Accuracy :  0.0125\n",
      "Step :  499  Loss :  0.5517733968574055  Accuracy :  0.012\n",
      "Step :  599  Loss :  0.45515803269420824  Accuracy :  0.006666666666666667\n",
      "Step :  699  Loss :  0.36665515959771855  Accuracy :  0.011428571428571429\n",
      "Step :  799  Loss :  0.34975873908793714  Accuracy :  0.01125\n",
      "Step :  899  Loss :  0.3087302112527687  Accuracy :  0.0033333333333333335\n",
      "Step :  999  Loss :  0.26104485733962474  Accuracy :  0.004\n",
      "Step :  1099  Loss :  0.24743295807808394  Accuracy :  0.00909090909090909\n",
      "Step :  1199  Loss :  0.23217578529297167  Accuracy :  0.005833333333333334\n",
      "Step :  1299  Loss :  0.23249905523176853  Accuracy :  0.002307692307692308\n",
      "Step :  1399  Loss :  0.2035744655113632  Accuracy :  0.002857142857142857\n",
      "Step :  1499  Loss :  0.17562453079284815  Accuracy :  0.006\n",
      "Step :  1599  Loss :  0.17082531905376702  Accuracy :  0.00375\n",
      "Step :  1699  Loss :  0.1619676122591756  Accuracy :  0.002352941176470588\n",
      "Step :  1799  Loss :  0.15269454494659238  Accuracy :  0.0011111111111111111\n",
      "Step :  1899  Loss :  0.13911518157830852  Accuracy :  0.004736842105263158\n",
      "Step :  1999  Loss :  0.13578853060582582  Accuracy :  0.003\n",
      "Step :  2099  Loss :  0.13898806016344104  Accuracy :  0.0019047619047619048\n",
      "Step :  2199  Loss :  0.1267171557209947  Accuracy :  0.004090909090909091\n",
      "Step :  2299  Loss :  0.1229343259698377  Accuracy :  0.003043478260869565\n",
      "Step :  2399  Loss :  0.11099271006037298  Accuracy :  0.0020833333333333333\n",
      "Step :  2499  Loss :  0.11228874955172048  Accuracy :  0.0012\n",
      "Step :  2599  Loss :  0.10508837848711708  Accuracy :  0.0019230769230769232\n",
      "Step :  2699  Loss :  0.10156883162081487  Accuracy :  0.0014814814814814814\n",
      "Step :  2799  Loss :  0.09959964449016045  Accuracy :  0.0017857142857142857\n",
      "Step :  2899  Loss :  0.0888806011990203  Accuracy :  0.000689655172413793\n",
      "Step :  2999  Loss :  0.09019182903532025  Accuracy :  0.0016666666666666668\n",
      "Step :  3099  Loss :  0.0925399726236381  Accuracy :  0.000967741935483871\n",
      "Step :  3199  Loss :  0.08590270707157863  Accuracy :  0.0021875\n",
      "Step :  3299  Loss :  0.082343379469349  Accuracy :  0.0015151515151515152\n",
      "Step :  3399  Loss :  0.08105627621155934  Accuracy :  0.0017647058823529412\n",
      "Step :  3499  Loss :  0.07853588580120541  Accuracy :  0.002857142857142857\n",
      "Step :  3599  Loss :  0.07502601359976979  Accuracy :  0.001388888888888889\n",
      "Step :  3699  Loss :  0.07790297330019609  Accuracy :  0.002162162162162162\n",
      "Step :  3799  Loss :  0.07548108258709633  Accuracy :  0.0010526315789473684\n",
      "Step :  3899  Loss :  0.07140850221595409  Accuracy :  0.0007692307692307692\n",
      "Step :  3999  Loss :  0.07408994057807988  Accuracy :  0.002\n",
      "Step :  4099  Loss :  0.06853381505151888  Accuracy :  0.0017073170731707317\n",
      "Step :  4199  Loss :  0.06338664974179517  Accuracy :  0.0016666666666666668\n",
      "Step :  4299  Loss :  0.06341654075157689  Accuracy :  0.0016279069767441861\n",
      "Step :  4399  Loss :  0.06204410626361672  Accuracy :  0.0022727272727272726\n",
      "Step :  4499  Loss :  0.059552753080926675  Accuracy :  0.0011111111111111111\n",
      "Step :  4599  Loss :  0.061440681073678845  Accuracy :  0.0006521739130434783\n",
      "Step :  4699  Loss :  0.06005472338671059  Accuracy :  0.0014893617021276596\n",
      "Step :  4799  Loss :  0.05762148405025782  Accuracy :  0.001875\n",
      "Step :  4899  Loss :  0.060674062267177115  Accuracy :  0.0006122448979591836\n",
      "Step :  4999  Loss :  0.05142951930794433  Accuracy :  0.002\n",
      "Step :  5099  Loss :  0.054216890203079  Accuracy :  0.001176470588235294\n",
      "Step :  5199  Loss :  0.054184506548540706  Accuracy :  0.000576923076923077\n",
      "Step :  5299  Loss :  0.05162621254555262  Accuracy :  0.0005660377358490566\n",
      "Step :  5399  Loss :  0.05443827775712802  Accuracy :  0.0007407407407407407\n",
      "Step :  5499  Loss :  0.051074088201676957  Accuracy :  0.0009090909090909091\n",
      "Step :  5599  Loss :  0.04799456859220616  Accuracy :  0.002142857142857143\n",
      "Step :  5699  Loss :  0.048730526709602394  Accuracy :  0.0014035087719298245\n",
      "Step :  5799  Loss :  0.0490433550302601  Accuracy :  0.00017241379310344826\n",
      "Step :  5899  Loss :  0.04639998391631139  Accuracy :  0.0005084745762711864\n",
      "Step :  5999  Loss :  0.04681992088493579  Accuracy :  0.0011666666666666668\n",
      "Step :  6099  Loss :  0.04806360909320099  Accuracy :  0.0003278688524590164\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m num_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i , (im, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(x_train, y_train)): \n\u001b[0;32m---> 28\u001b[0m     softmax_out , l , acc \u001b[38;5;241m=\u001b[39m \u001b[43mforwrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     29\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l \n\u001b[1;32m     30\u001b[0m     num_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc \n",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36mforwrad\u001b[0;34m(image, label)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforwrad\u001b[39m(image , label): \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# une fonction qui fait forward sur une image et son label \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     conv_out \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 26x26x8\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     pool_out \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mforward(conv_out) \u001b[38;5;66;03m# 13x13x8\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     softmax_out \u001b[38;5;241m=\u001b[39m softmax\u001b[38;5;241m.\u001b[39mforward(pool_out) \u001b[38;5;66;03m# 10 classes \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m, in \u001b[0;36mConv3x.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     28\u001b[0m output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((h \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m, w \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_filters)) \n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im_region, i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate_regions(\u001b[38;5;28minput\u001b[39m): \n\u001b[0;32m---> 30\u001b[0m     output[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_region\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "conv = Conv3x(8)\n",
    "pool = MaxPool2()\n",
    "softmax = Softmax(13 * 13 * 8, 10) # 10 classes pour mnist\n",
    "\n",
    "\n",
    "def forwrad(image , label): \n",
    "    # une fonction qui fait forward sur une image et son label \n",
    "    conv_out = conv.forward(image) # 26x26x8\n",
    "    pool_out = pool.forward(conv_out) # 13x13x8\n",
    "    softmax_out = softmax.forward(pool_out) # 10 classes \n",
    "\n",
    "    #caccul la crooss entropy et l accuracy \n",
    "\n",
    "\n",
    "    loss = -np.log(softmax_out[label])\n",
    "    acc = 1 if np.argmax(softmax_out) == label else 0\n",
    "\n",
    "    return softmax_out , loss , acc\n",
    "\n",
    "\n",
    "print(\"Mnist CNN\") \n",
    "\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "\n",
    "\n",
    "for i , (im, label) in enumerate(zip(x_train, y_train)): \n",
    "    softmax_out , l , acc = forwrad(im , label) \n",
    "    loss += l \n",
    "    num_correct += acc \n",
    "\n",
    "    if i % 100 == 99: \n",
    "        print(\"Step : \", i , \" Loss : \", loss / (i + 1), \" Accuracy : \", num_correct / (i + 1))\n",
    "        loss = 0\n",
    "        num_correct = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
